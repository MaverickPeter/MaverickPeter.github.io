<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="About Robotics, SLAM & Society | Robot Lover，SLAM Algorithm Student, ZJUer & HFLSer | 这里是 @Maverick许学成 的个人博客，与你一起发现世界。">
    <meta name="keywords"  content="许学成, Maverickp, 雪城, @我不是自信, 许学成的博客, Maverickp Blog, 博客, 个人网站, Robotics, Semantic SLAM">
    <meta name="theme-color" content="#000000">
    
    <title>Portfolio - 许学成的博客 | Maverickp Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://localhost:4000/portfolio/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Maverickp Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    <li>
                        <a href="/portfolio/">Portfolio</a>
                    </li>
                    
                    <li>
                        <a href="/tags/">Tags</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    var __HuxNav__ = {
        close: function(){
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        },
        open: function(){
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }

    // Bind Event
    $toggle.addEventListener('click', function(e){
        if ($navbar.className.indexOf('in') > 0) {
            __HuxNav__.close()
        }else{
            __HuxNav__.open()
        }
    })

    /**
     * Since Fastclick is used to delegate 'touchstart' globally
     * to hack 300ms delay in iOS by performing a fake 'click',
     * Using 'e.stopPropagation' to stop 'touchstart' event from 
     * $toggle/$collapse will break global delegation.
     * 
     * Instead, we use a 'e.target' filter to prevent handler
     * added to document close HuxNav.  
     *
     * Also, we use 'click' instead of 'touchstart' as compromise
     */
    document.addEventListener('click', function(e){
        if(e.target == $toggle) return;
        if(e.target.className == 'icon-bar') return;
        __HuxNav__.close();
    })
</script>


    <!DOCTYPE html>
<html class="no-js">
	<head>
		<meta charset="UTF-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>Maverickp - Timeline</title>
		<link rel="stylesheet" type="text/css" href="css/timeline.css" />
		<script src="js/modernizr.custom.js"></script>
	</head>
	<body>
		<div class="container" style="margin:0;padding:0;width:100%;">
			<header>
				<img width="175" height="175" style="border-radius:50%;" src="/img/avatar-xxc.jpg">
				<h1>Maverickp</h1>
			</header>
			<div class="main">
				<ul class="cbp_tmtimeline">
                    <li>
						<div class="cbp_tmlabel">
							<h2 id="Paper">Paper - DiSCO: Differentiable Scan Context with Orientation </h2>
							<time>2020.10</time>
							<img src="images/portfolio-DiSCO.png">
							<ul>
								<li>
                                    Global localization is essential for robot navigation, of which the first step is to retrieve a query from the map database. This problem is called place recognition. In recent years, LiDAR scan based place recognition has drawn attention as it is robust against the environmental change. In this paper, we propose a LiDAR-based place recognition method, named Differentiable Scan Context with Orientation (DiSCO), which simultaneously finds the scan at a similar place and estimates their relative orientation. The orientation can further be used as the initial value for the down-stream local optimal metric pose estimation, improving the pose estimation especially when a large orientation between the current scan and retrieved scan exists.                                 
                                </li>
								<li class="skill">
                                    <span><b>DL</b></span>
                                    <span><b>3D</b></span>
									<span class="i-ubuntu"></span>
									<span class="link"><a target="_blank" href="https://arxiv.org/abs/2010.10949">Paper</a></span>
								</li>
							</ul>
						</div>
                    </li>
                    <li>
						<div class="cbp_tmlabel">
							<h2 id="Paper">Paper - Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements Matching</h2>
							<time>2020.06</time>
							<img src="images/portfolio-DPCN.png">
							<ul>
								<li>
                                    <b>[2020 The Conference on Robot Learning (CoRL)]</b> <br>The crucial step for localization is to match the current observation to the map. When the two sensor modalities are significantly different, matching becomes challenging. In this paper, we present an end-to-end deep phase correlation network (DPCN) to match heterogeneous sensor measurements. In DPCN, the primary component is a differentiable correlation-based estimator that back-propagates the pose error to learnable feature extractors, which addresses the problem that there are no direct common features for supervision. Also, it eliminates the exhaustive evaluation in some previous methods, improving efficiency. With the interpretable modeling, the network is light-weighted and promising for better generalization.                                
                                </li>
								<li class="skill">
                                    <span><b>DL</b></span>
                                    <span><b>CV</b></span>
                                    <span class="i-ros"></span>
									<span class="i-ubuntu"></span>
									<span class="link"><a target="_blank" href="https://arxiv.org/abs/2008.09474">Paper</a></span>
								</li>
							</ul>
						</div>
                    </li>
                    <li>
						<div class="cbp_tmlabel">
							<h2 id="Paper">Paper - Collaborative Localization of Aerial and Ground Mobile Robots through Orthomosaic Map</h2>
							<time>2020.04</time>
							<img src="images/portfolio-RCAR.png">
							<ul>
								<li>
                                    <b>[2020 International Conference on Real-time Computing and Robotics (RCAR)]</b> <br>With the deepening of research on the SLAM system, the possibility of cooperative SLAM with multi-robots has been proposed. This paper presents a map matching and localization approach considering the cooperative SLAM of an aerial-ground system. The proposed approach aims to help precisely matching the map constructed by two independent systems that have large scale variance of viewpoints of the same route and eventually enables the ground mobile robot to localize itself in the global map given by the drone.                               
                                </li>
								<li class="skill">
                                    <span><b>CV</b></span>
                                    <span class="i-ros"></span>
									<span class="i-ubuntu"></span>
									<span class="link"><a target="_blank" href="https://arxiv.org/abs/2007.11233">Paper</a></span>
								</li>
							</ul>
						</div>
                    </li>
                    <li>
						<div class="cbp_tmlabel">
							<h2 id="Paper">Paper - GEM: online globally consistent dense elevation mapping for unstructured terrain</h2>
							<time>2020.02</time>
							<img src="images/portfolio-GEM.png">
							<ul>
								<li>
                                    We propose an elevation mapping system, namely GEM, to generate a dense local elevation map in constant real-time for fast responsive local planning, and maintain a globally consistent dense map for path routing at the same time.
                                </li>
								<li class="skill">
                                    <span><b>SLAM</b></span>
                                    <span class="i-ros"></span>
									<span class="i-ubuntu"></span>
									<!-- <span class="link"><a target="_blank" href="https://maverickpeter.github.io/GEM.pdf">Paper</a></span> -->
								</li>
							</ul>
						</div>
                    </li>
                    <li>
						<div class="cbp_tmlabel">
							<h2 id="Paper">Paper - Real-time instance-aware semantic mapping </h2>
							<time>2019.11</time>
							<img src="images/portfolio-semantics.png">
							<ul>
								<li>
                                    <b>[Journal of Physics: Conference Series (2019 ICDT Conference)]</b> <br> The semantic information helps robots to understand its surroundings like human beings and enables robots to achieve human-robot interaction. In recent years, there have been many interests in semantic mapping. Numerous approaches manage to build a semantic map and achieve good accuracy, but the existing mapping methods which create the metric semantic map ignore the subsequent applications of the semantic map. However, the metric map with the simple semantic class label has no direct benefit to localization. In this paper, we propose an approach to construct an object-centric map with promising applications.
                                </li>
								<li class="skill">
                                    <span><b>SLAM</b></span>
                                    <span class="i-ros"></span>
									<span class="i-ubuntu"></span>
									<!-- <span class="link"><a target="_blank" href="https://maverickpeter.github.io/GEM.pdf">Paper</a></span> -->
								</li>
							</ul>
						</div>
                    </li>
                    <li>
						<div class="cbp_tmlabel">
							<h2 id="Paper">Paper - GPU accelerated real-time traversability mapping </h2>
							<time>2019.09</time>
							<img src="images/portfolio-gpu-GEM.png">
							<ul>
								<li>
                                    <b>[2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)]</b> <br>Dense map representation of the robot surroundings, which contains detailed information of the drivable region can be easily used for motion planning. To build a dense map on mobile robots, the main challenge is that the system has to be efficient due to the limited computational resources. In this paper, we propose a novel approach to generate a dense map with drivable information. First, the dense map with elevation information is generated by the proprioceptive localization results acquired from kinematic and inertial measurement, as well as the accumulated raw data from the range sensor. 
                                </li>
								<li class="skill">
                                    <span><b>CUDA</b></span>
                                    <span><b>SLAM</b></span>
                                    <span class="i-ros"></span>
									<span class="i-ubuntu"></span>
									<span class="link"><a target="_blank" href="https://ieeexplore.ieee.org/document/8961816">Paper</a></span>
								</li>
							</ul>
						</div>
					</li>
                    <li>
						<div class="cbp_tmlabel">
							<h2 id="Project">Graduate Thesis - Semantic Mapping</h2>
							<time>2019.03</time>
							<img src="images/portfolio-semantic-mapping.png">
							<ul>
								<li>
                                    In order to improve the perception ability of mobile robots, there is a fashion to import object infomation in the process of SLAM, a most common one is semantic mapping. In my Graduate thesis, I developed a mapping system based on the RNN and semantic segmentation.
                                </li>
								<li class="skill">
									<span><b>CV</b></span>
									<span class="i-ubuntu"></span>
									<span class="link"><a target="_blank" href="https://maverickpeter.github.io/graduate-thesis.pdf">Thesis</a></span>
								</li>
							</ul>
						</div>
					</li>
					<li>
						<div class="cbp_tmlabel">
							<h2 id="Intern">Intern @Nanjiang Robotics</h2>
							<time>2018.08</time>
							<img src="images/portfolio-3d-mapping.png">
							<ul>
								<li>
									As a <b>Intern Algorithm Engineer</b>, I developed a feature-based 3d mapping method using sensor - Quanergy M8. The feature-based map is used to describe the depot environment which mainly consists of walls and girders. Test code can be found on github.
								</li>
								<li class="skill">
									<span><b>PCL</b></span>
									<span class="i-quanergy"></span>
									<span class="link"><a target="_blank" href="https://github.com/MaverickPeter/simple_mapping_3d">Github</a></span>
								</li>
							</ul>
						</div>
					</li>
					<li>
						<div class="cbp_tmlabel">
							<h2 id="Course">Course - Flight Vehicle Navigation and Control Technology</h2>
							<time>2018.07</time>
							<img src="images/portfolio-uav-model.png">
							<ul>
								<li>
									In this course, I had the chance to get more basic knowledge of the plane and the quadrotor. I was attracted by the knowledge of the quadrotor for I just had finished some application projects on this platform. In order to have a deeper understanding, I modeled a quadrotor with motion equations and force constraints and built a rather practical model in Matlab Simulink. I even managed to control the quadrotor using PID and cascade PID.
								</li>
								<li class="skill">
									<span><b>PID</b></span>
									<span class="i-matlab"></span>
								</li>
							</ul>
						</div>
					</li>
					<li>
						<div class="cbp_tmlabel">
							<h2 id="Competition">ICRA 2018 DJI RoboMaster AI Challenge</h2>
							<time>2018.05</time>
							<img src="images/portfolio-robomaster.jpg">
							<ul>
								<li>
									I attended ICRA 2018 DJI RoboMaster AI Challenge as a member of ZMART Team, ZJU. Our team got 12/21 in the final competition. <br>In this Challenge, the task was to defeat the official AI cars by building our own cars. In this situation, we built a robot based on ROS(Robot Operation System) with modules like decision, navigation, localization and so on. I was in charge of the <b>detecting and technical coordination</b>.
								</li>
								<li class="skill">
									<span class="i-ros"></span>
									<span class="link"><a target="_blank" href="https://www.robomaster.com/zh-CN/resource/pages/862?type=announcementSub">View</a></span>
								</li>
							</ul>
						</div>
					</li>
					<li>
						<div class="cbp_tmlabel">
							<h2 id="Project">UAV Precise Landing using infrared beacon</h2>
							<time>2018.05</time>
							<img src="images/portfolio-precise-landing.png">
							<ul>
								<li>
									This project is based on the previous work on putting out a fire using UAV. <br>I developed a robust two-step landing strategy to assure the landing precision. First, the UAV detects the AR Markers around the target and roughly goes to the top of it. Then, the infrared beacon continuously gives the robust signal to the UAV, so it can adjust its pose during the landing.
								</li>
								<li class="skill">
									<span><b>CV</b></span>
									<span class="i-ubuntu"></span>
								</li>
							</ul>
						</div>
					</li>
					<li>
						<div class="cbp_tmlabel">
							<h2 id="Course">Course - Advanced Experiment of Microprocessors & Interfacing</h2>
							<time>2018.01</time>
							<img src="images/portfolio-uav-throw.jpg">
							<ul>
								<li>
									This project demonstrates how a quadrotor can put out a fire. I used Raspberry Pi (model 3b) as a companion computer of the PIXHAWK (with apm firmware). There was a camera on the Pi to get the downward vision. With the pictures we got, we calculated the best throw-point and throw our "water ball" to the point.  
								</li>
								<li class="skill">
									<span class="i-ubuntu"></span>
									<span class="link"><a target="_blank" href="https://github.com/MaverickPeter/Copter_mavlink_companion_control">Github</a></span>
								</li>
							</ul>
						</div>
					</li>
					<li>
						<div class="cbp_tmlabel">
							<h2 id="Course">Course - Robots Technology</h2>
							<time>2018.01</time>
							<img src="images/portfolio-vrep.png">
							<ul>
								<li>
									This project was developed on the V-REP simulation environment. The task was to build a robot to grab a block and put it on the manipulator platform.<br> I loaded a model of a ready-made manipulator and modified it to a mobile manipulator. A camera and a distance sensor was installed on the end-effector to achieve visual servo. 
								</li>
								<li class="skill">
									<span class="i-vrep"></span>
								</li>
							</ul>
						</div>
					</li>
					<!--<li>
						<div class="cbp_tmlabel">
							<h2>SENOVA WebApp</h2>
							<img src="images/senova.jpg">
							<ul>
								<li>《多媒体交互设计一》结课作业，以北汽“绅宝”为目标品牌，iPad 为主要平台进行的 App 设计，旨在用一种可交互的方式介绍“绅宝”车型。完全采用 Html5 技术开发，可添加至主屏幕离线运行。着力于触控交互体验的优化与优雅的动画设计。</li>
								<li>Responsible : Front-End，Interaction，Product</li>
								<li>Partner : ZOE-张瑜</li>
								<li class="skill">
									<span class="cbp_tmicon-html"></span>
									<span class="fa fa-css3"></span>
									<span><b>JS</b></span>
									<span class="link"><a target="_blank" href="http://huangxuan.me/senova/">Link</a></span>
								</li>
							</ul>
						</div>
					</li>-->
				</ul>
			</div>
		</div>
	</body>
</html>


    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    

                    <!-- add Weibo, Zhihu by Hux, add target = "_blank" to <a> by Hux -->
                    
                    <li>
                        <a target="_blank" href="https://www.zhihu.com/people/xu-xue-cheng-77">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa  fa-stack-1x fa-inverse">知</i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a target="_blank" href="http://weibo.com/570055472">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    


                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/MaverickPeter">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Maverickp Blog 2019
                    <br>
                    Theme by <a href="http://huangxuan.me">Hux</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Service Worker -->

<script src="/js/snackbar.js "></script>
<script src="/js/sw-registration.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async('/js/jquery.tagcloud.js',function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->

<script>
    // dynamic User by Hux
    var _gaId = 'UA-134615500-1';
    var _gaDomain = 'maverickpeter.github.io';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>



<!-- Baidu Tongji -->



<!-- Side Catalog -->



<!-- Multi-Lingual -->




<!-- Image to hack wechat -->
<img src="/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
